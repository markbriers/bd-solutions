{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "week10-notes.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOlhovxaGu6R32cX2dZSd6y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/markbriers/bd-solutions/blob/master/week10_notes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vm7S_LHJfgeH"
      },
      "source": [
        " # Evaluation and module summary (Week 10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UKWy9ybMf6KW"
      },
      "source": [
        "## Learning outcome\n",
        "\n",
        "* By the end of the lecture, you will be able to use a universal metric (ROC AUC) for evaluating the quality of a model for binary classification.\n",
        "\n",
        "* By the end of the lecture, you will be able to describe and execute the CRISP-DM process, end-to-end, in order to start your career as a data science practitioner."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iGxTZlN2hT_E"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W95tpUe0hkS4"
      },
      "source": [
        "Evaluation of a data science project requires one to evaluate each stage in the process:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XrLF5wD0hC71"
      },
      "source": [
        "<img src=\"https://drive.google.com/uc?id=1kyHsPTtVtIuqQPOXSd380SK733rWyqqT\" alt=\"vector-scalar\" style=\"width: 550px;height: 500px\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0lF6L6gSh7Pq"
      },
      "source": [
        "* _Business understanding_: How well have we captured the business requirements? Will the project output allow stakeholders to make the decisions they wish? (Did we capture the appropriate action space? Have they been engaged with the project? What's their feedback?)\n",
        "* _Data understanding and data preparation_: Do we have a good understanding of the statistical properties of the data? Can we independently verify this? Do we have any new data that could be used to verify the findings and assumptions? Is our code of sufficient quality? Have we considered all ethical, legal and equalities issues? Do the results have the potential to cause unitended harm?\n",
        "* _Modelling_: How well does any model extrapolate to population based inference? (See below for binary classification.)\n",
        "* _Overall_: How well was the process executed? Can we list our assumptions? How well are we meeting our measures of impact (indicators)? Do we have a plan for transition to BAU (deployment)? Do we need to continually monitor any automated solution for context drift? If so, how is this going to be performed? What are the risks associated with deployment?\n",
        "\n",
        "_Recap_: Indicators allow us to consider how well the data science project is performing against the objectives and associated success measures. For each objective / success measure pair, we would expect to have a set of indicator defintions as follows:\n",
        "\n",
        "- Indicator description;\n",
        "- Frequency of reporting;\n",
        "- Source location;\n",
        "- Availability;\n",
        "- Responsible owner;\n",
        "- Indicator target;\n",
        "- Due date.\n",
        "\n",
        "The definition of indicators are critical to assessing, communicating, and shaping the project's business impact.\n",
        "\n",
        "Examples of indicators could be related to the discriminative power of a modelling sytem, the reduction in time taken to make a decision, a binary state of quality assurance, and so on."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rV-0XKS2jhIy"
      },
      "source": [
        "## Model assessment - binary classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AM1Yrm0KjkL3"
      },
      "source": [
        "Let's consider the following table (taken from https://en.wikipedia.org/wiki/Receiver_operating_characteristic#Basic_concept)\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?id=1KnG34A7j5H3DdadtpYX-ek7Ra7XDgSPy\" alt=\"vector-scalar\" style=\"width: 550px;height: 500px\"/>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E3hmBQ5rnluV"
      },
      "source": [
        "A binary classification algorithm is used to differentiate between positive and negative examples (e.g. spam or not spam). The output of a classification algorithm will be an assessment - often probabilistic - of the class membership of a data point (or features derived from the data point). In order to convert this assessment into a definitive solution (e.g. spam or not spam) then a classification algorithm requires a threshold. E.g. probability of x=0 (not spam) is greater than 0.7. Choosing a threshold will change the numebr of true positives / false positives. To understand this, consider the extreme case where all data points are allocated as not spam (probability threshold for x=0 equal to 0.0). In this case, the false negative rate will be higher than may be acceptable (the spam filter is not working!). Conversely, consider the case where all data items are classified as spam (probability threshold for x=0 equal to 1.0). The false positive rate in this case may be unacceptably high (no emails will ever be recieved by users!). So a decision needs to be made as to the threshold chosen, how this relates to TPR / FPR, and what this means for the satisfying the business objective. The best way to visualise this is through the Receiver Operating Characteristic:\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?id=1ds5dueCJykoa7xv42bkMqE5yXy7PAX9_\" alt=\"vector-scalar\" style=\"width: 550px;height: 500px\"/>\n",
        "\n",
        "(Diagram from: MartinThoma - Own work, CC0, https://commons.wikimedia.org/w/index.php?curid=70212136)\n",
        "\n",
        "The ROC curve allows us to understand the trade-off between the TPR and FPR for different thresholds, and to compare classification performance through a measure called ROC Area Under the Curve (AUC). The ROC AUC measure allows us to assess the discriminative performance of the classification algorithm; it is the area under the ROC curve, a value between 0 and 1. A classifier with a ROC AUC value of 0.5 is considered random. A classifier with an ROC AUC value above 0.8 is considered to be excellent. So, when evaluating classification performance, it's important to consider the discriminative ability (via ROC AUC) and the suitability of TPR / FPR performance for a given business problem."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZ_mMXPKstab"
      },
      "source": [
        "### Case study: NHS COVID-19 app\n",
        "\n",
        "The NHS COVID-19 determines the risk associated between two individuals: an individual that has been confirmed as testing positive for COVID-19, and a user that has been within 2m for 15mins. It does this using Bluetooth Low Energy measurements, using a sophisticated statistical procedure, and an epidemilogically valid risk function. The decision as to whether to inform the user to isolate or not is based on a threshold: has the risk a potentially affected user has faced greater than an acceptable threshold? By choosing such a threshold, what's the public health consequences, and the consequences to individuals' rights to freedom? This is a complex policy decision. The ROC AUC of the NHS COVID-19 app is 0.84. Its discriminative performance is considered excellent. The threshold has been set to ensure that the TPR=0.7. This was on the basis of an analysis of the ROC:\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?id=1_aMGBnptm0bicU_SPvNaWYGHrlyNimNv\" alt=\"vector-scalar\" style=\"width: 550px;height: 500px\"/>\n",
        "\n",
        "\n",
        "\n",
        "We continually monitor the performance of the app, using measures described here, and as describedin this blog post: https://www.turing.ac.uk/blog/demonstrating-impact-nhs-covid-19-app."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LpwXHN8Kfs2h"
      },
      "source": [
        "***\n",
        "\n",
        "## Summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X0P82Nh3froI"
      },
      "source": [
        "Our goal is to follow a data science process (CRISP-DM) to deliver a successful business outcome.\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?id=1kyHsPTtVtIuqQPOXSd380SK733rWyqqT\" alt=\"vector-scalar\" style=\"width: 550px;height: 500px\"/>\n",
        "\n",
        "Our learning objectives are as follows:\n",
        "\n",
        "* Describe the six stages of a data processing pipeline (using CRISP-DM)\n",
        "\n",
        "* Demonstrate an understanding of the python programming language through the production of elementary data analysis programme\n",
        "\n",
        "* Analyse at least three different data sources by applying at least one python data processing library to extract and explore pertinent features\n",
        "\n",
        "* Be able to design a set of data requirements for a specified business problem\n",
        "\n",
        "* Describe and apply (using the python programming language) the main approaches to supervised learning for a given classification problem\n",
        "\n",
        "* Understand the use cases of Big Data technology (in particular Spark)\n",
        "\n",
        "* Produce a report including appropriate data visualisations covering the analysis of a business problem using a data science based approach"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5LVQpqXpnT6E"
      },
      "source": [
        "***\n",
        "\n",
        "Thank you!"
      ]
    }
  ]
}